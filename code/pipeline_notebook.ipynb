{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4e3c28c",
   "metadata": {},
   "source": [
    "# Historical Speeches to Clips - Execution Notebook\n",
    "\n",
    "This notebook is intended to leverage the classes and functions of the HSC package in order to create an interactive pipeline for generating 1 minute long clips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acbdcd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell controls the auto reloading of packages - disable to save time if not in development mode\n",
    "%load_ext autoreload\n",
    "# %reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b53ee7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to System Path: C:\\Users\\cjmij\\z_projects\\historical_speech_project\\code\\scripts\n",
      "Added to System Path: C:\\Users\\cjmij\\z_projects\\historical_speech_project\\code\\captions\n"
     ]
    }
   ],
   "source": [
    "# Path and System Configuration\\n,\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "root = Path.cwd().resolve().parent\n",
    "scripts_path = root / \"code\" / \"scripts\"\n",
    "captions_path = root / \"code\" / \"captions\"\n",
    "\n",
    "if str(scripts_path) not in sys.path:\n",
    "    sys.path.insert(0, str(scripts_path))\n",
    "    print(\"Added to System Path:\", scripts_path)\n",
    "\n",
    "if str(captions_path) not in sys.path:\n",
    "    sys.path.insert(0, str(captions_path))\n",
    "    print(\"Added to System Path:\", captions_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71adb041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# External Package Imports\n",
    "import json, os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Internal Scripts Package Imports\n",
    "from scripts.ingest import ingest_folder\n",
    "from scripts.deepgram_model import generate_deepgram_audio\n",
    "from scripts.video_generator import create_video\n",
    "from scripts.video_generator_221_advanced import create_video_ffmpeg\n",
    "\n",
    "\n",
    "# Internal Captions Package Imports\n",
    "from captions.caption_generator import prepare_file_for_adding_captions_n_headings_thru_html\n",
    "from captions.line_level_captions_adv import split_lines_with_capitalization\n",
    "from captions.video_with_captions_adv import create_video_with_captions_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b4afb9",
   "metadata": {},
   "source": [
    "# Section 0: Setup File Paths and Project Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61b32513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where you set the text you want to create the video for\n",
    "text_to_process = \"federalist-10\"\n",
    "# Set the background image that will be shared across video files\n",
    "background_image = \"James_Madison.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05134059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup directory paths for specific raw text file\n",
    "RAW_TEXT_DIR = Path(f\"../data/raw_texts/{text_to_process}\")\n",
    "PROCESSED_TEXT_DIR = Path(\"../data/processed_texts\")\n",
    "\n",
    "TEXT_CHUNKS_DIR = Path(f\"../data/processed_texts/{text_to_process}_chunks\")\n",
    "BACKGROUND_DIR = Path(\"../assets/backgrounds\")\n",
    "BACKGROUND_IMAGE_PATH = Path(f\"{BACKGROUND_DIR}/{background_image}\")\n",
    "OVERLAY_IMAGE_DIR = Path(f\"../assets/overlay_images\")\n",
    "\n",
    "PROCESSED_AUDIO_DIR = Path(f\"../data/processed_audio/{text_to_process}_chunks\")\n",
    "BASIC_VIDEO_OUTPUT_DIR = Path(f\"../data/video_output/{text_to_process}/basic\")\n",
    "CAPTION_VIDEO_OUTPUT_DIR = Path(f\"../data/video_output/{text_to_process}/caption\")\n",
    "\n",
    "WORD_CAPTION_JSON_DIR = Path(f\"../data/captions/{text_to_process}/word_timestamps\")\n",
    "LINE_CAPTION_JSON_DIR = Path(f\"../data/captions/{text_to_process}/line_timestamps\")\n",
    "IMAGE_CAPTION_JSON_DIR = Path(f\"../data/captions/{text_to_process}/image_timestamps\")\n",
    "\n",
    "# Ensure all necessary directories exist\n",
    "for d in [\n",
    "    RAW_TEXT_DIR,\n",
    "    PROCESSED_TEXT_DIR,\n",
    "    TEXT_CHUNKS_DIR,\n",
    "    BACKGROUND_DIR,\n",
    "    OVERLAY_IMAGE_DIR,\n",
    "    PROCESSED_AUDIO_DIR,\n",
    "    BASIC_VIDEO_OUTPUT_DIR,\n",
    "    CAPTION_VIDEO_OUTPUT_DIR,\n",
    "    WORD_CAPTION_JSON_DIR,\n",
    "    LINE_CAPTION_JSON_DIR,\n",
    "    IMAGE_CAPTION_JSON_DIR,\n",
    "]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load environment variables from ../.env\n",
    "load_dotenv(dotenv_path=Path(\"../.env\"))\n",
    "DEEPGRAM_API_KEY = os.getenv(\"DEEPGRAM_API_KEY\")\n",
    "PEXELS_API_KEY = os.getenv(\"PEXELS_API_KEY\")\n",
    "REPLICATE_API_KEY = os.getenv(\"REPLICATE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2e1fd4",
   "metadata": {},
   "source": [
    "# Section 1: Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeab9b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the main ingestion process that takes the text and breaks it into different sized chunks\n",
    "# These parameters will control the length of each video and the total number of chunks generated\n",
    "# ingest_folder(RAW_TEXT_DIR, PROCESSED_TEXT_DIR, target_seconds=65, wpm=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3706d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((TEXT_CHUNKS_DIR / \"manifest.json\").read_text()[:464], \"...\\n\")\n",
    "\n",
    "# Peek first chunk\n",
    "first = sorted(TEXT_CHUNKS_DIR.glob(\"*.json\"))\n",
    "first = [p for p in first if p.name != \"manifest.json\"][0]\n",
    "chunk = json.loads(first.read_text(encoding=\"utf-8\"))\n",
    "chunk[\"chunk_id\"], chunk[\"approx_word_count\"], chunk[\"est_duration_sec\"], chunk[\"text\"][:200] + \"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42a27e4",
   "metadata": {},
   "source": [
    "# Section 2: Deepgram TTS Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f067ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all chunk files except manifest.json\n",
    "chunk_files = sorted([p for p in TEXT_CHUNKS_DIR.glob(\"*.json\") if p.name != \"manifest.json\"])\n",
    "\n",
    "# This setup will create a multitude of mp3 files based on the contents of the chunks dir variable\n",
    "\n",
    "# for chunk_path in chunk_files:\n",
    "# # if chunk_files:\n",
    "# #     chunk_path = chunk_files[0]\n",
    "#     current = json.loads(chunk_path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "#     temp_out_file_name = Path(f\"{PROCESSED_AUDIO_DIR}/{current['chunk_id']}-tts.mp3\")\n",
    "#     temp_out_file_name.parent.mkdir(parents=True, exist_ok=True)\n",
    "#     temp_input_text = {\"text\": current[\"text\"]}\n",
    "\n",
    "#     generate_deepgram_audio(local_api_key=DEEPGRAM_API_KEY, \n",
    "#                             out_file_name=str(temp_out_file_name),\n",
    "#                             input_text=temp_input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7e6669",
   "metadata": {},
   "source": [
    "# Section 3: Merging Audio and Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d358d923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all mp3 files from the processed audio directory\n",
    "mp3_files = sorted([p for p in PROCESSED_AUDIO_DIR.glob(\"*.mp3\")])\n",
    "\n",
    "print(f\"Found {len(mp3_files)} mp3 files to process for video creation.\")\n",
    "\n",
    "# for idx, file in enumerate(mp3_files, 1):\n",
    "#     print(f\"[{idx}/{len(mp3_files)}] Creating video for audio: {file.name}\")\n",
    "#     create_video(\n",
    "#         image_path=BACKGROUND_IMAGE_PATH,\n",
    "#         audio_path=file,\n",
    "#         output_path=BASIC_VIDEO_OUTPUT_DIR,\n",
    "#         target_size=(1080, 1920)\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8068ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp4_files = sorted([p for p in BASIC_VIDEO_OUTPUT_DIR.glob(\"*.mp4\")])\n",
    "\n",
    "print(f\"\\nFound {len(mp4_files)} mp4 files to process for caption JSON generation.\")\n",
    "\n",
    "# for idx, file in enumerate(mp4_files, 1):\n",
    "#     file_stem = file.stem  # gets the filename without the suffix as a string\n",
    "#     out_json_word_path = Path(f\"{WORD_CAPTION_JSON_DIR}/{file_stem}.json\")\n",
    "#     out_json_line_path = Path(f\"{LINE_CAPTION_JSON_DIR}/{file_stem}.json\")\n",
    "\n",
    "#     print(f\"[{idx}/{len(mp4_files)}] Preparing JSON for: {file.name}\")\n",
    "#     prepare_file_for_adding_captions_n_headings_thru_html(input_video_path=file, \n",
    "#                                                         out_json_path=out_json_word_path)\n",
    "    \n",
    "#     print(f\"[{idx}/{len(mp4_files)}] Splitting lines with capitalization for: {file.name}\")\n",
    "#     split_lines_with_capitalization(out_json_word_path, out_json_line_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e95806",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nAdding captions to {len(mp4_files)} videos.\")\n",
    "\n",
    "# for idx, file in enumerate(mp4_files, 1):\n",
    "#     file_stem = file.stem  # e.g., \"video1\"\n",
    "#     json_line_path = LINE_CAPTION_JSON_DIR / f\"{file_stem}.json\"\n",
    "\n",
    "#     # Ensure output file has .mp4 extension and \"-caption\" suffix before extension\n",
    "#     out_caption_video_name = f\"{file_stem}-caption.mp4\"\n",
    "#     out_caption_video_path = CAPTION_VIDEO_OUTPUT_DIR / out_caption_video_name\n",
    "\n",
    "#     print(f\"[{idx}/{len(mp4_files)}] Creating captioned video for: {out_caption_video_name}\")\n",
    "#     create_video_with_captions_adv(\n",
    "#         mp4_file=file,\n",
    "#         linelevel_timestamps=json_line_path,\n",
    "#         video_out_path=out_caption_video_path,\n",
    "#         font=\"COPRGTB\"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142e5b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import font_manager\n",
    "\n",
    "# # Collect all available system fonts\n",
    "# available_fonts = font_manager.findSystemFonts(fontpaths=None, fontext='ttf')\n",
    "\n",
    "# # Print font file paths\n",
    "# for font_path in available_fonts:\n",
    "#     print(font_path)\n",
    "\n",
    "# # Optional: get the \"family name\" from each font\n",
    "# from matplotlib import font_manager\n",
    "# for font_path in available_fonts[:10]:  # just first 10\n",
    "#     font_prop = font_manager.FontProperties(fname=font_path)\n",
    "#     print(font_prop.get_name())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2677e218",
   "metadata": {},
   "source": [
    "# Section 4: Adding Additional Visual Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0510e0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from video_inserts.keyphrase_extractor import extract_keyphrases\n",
    "from video_inserts.create_inserts_from_timestamps import build_inserts_for_chunk\n",
    "\n",
    "chunk_files = sorted([p for p in TEXT_CHUNKS_DIR.glob(\"*.json\") if p.name != \"manifest.json\"])\n",
    "\n",
    "for chunk_path in chunk_files:\n",
    "# if chunk_files:\n",
    "#     chunk_path = chunk_files[0]\n",
    "    current = json.loads(chunk_path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "    current_word_ts = Path(f\"{WORD_CAPTION_JSON_DIR}/{chunk_path.stem}-tts.json\")\n",
    "    word_ts = json.loads(current_word_ts.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "    # temp_out_file_name = Path(f\"{PROCESSED_AUDIO_DIR}/{current['chunk_id']}-tts.mp3\")\n",
    "    # temp_out_file_name.parent.mkdir(parents=True, exist_ok=True)\n",
    "    temp_input_text = {\"text\": current[\"text\"]}\n",
    "    phrases = extract_keyphrases(current[\"text\"], top_k=15)\n",
    "\n",
    "    # for i, p in enumerate(phrases, 1):\n",
    "    #     print(f\"{i}. {p}\")\n",
    "\n",
    "    inserts_doc = build_inserts_for_chunk(\n",
    "        wordlevel_json=word_ts,\n",
    "        phrases=phrases,\n",
    "        fps=24,\n",
    "        min_duration=4.5,  # tune per your pacing\n",
    "        pad_pre=0.1,\n",
    "        pad_post=0.0,\n",
    "        min_start_time=4.0,\n",
    "        avoid_overlaps=True,\n",
    "        gap_after=2.0\n",
    "    )\n",
    "    \n",
    "    image_caption_json_path = Path(f\"{IMAGE_CAPTION_JSON_DIR}/{chunk_path.stem}-img-caption.json\")\n",
    "    image_caption_json_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    image_caption_json_path.write_text(json.dumps(inserts_doc, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "\n",
    "    # import pprint\n",
    "    # pprint.pprint(inserts_doc, sort_dicts=False, width=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e52ae0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] reconcile_inserts: Loading inserts JSON: ..\\data\\captions\\federalist-10\\image_timestamps\\federalist-10-part-01-img-caption.json\n",
      "[INFO] reconcile_inserts: Found 4 phrase(s) from inserts[*]['reason'].\n",
      "[INFO] reconcile_inserts: 4 unique phrase(s) after de-duplication.\n",
      "[INFO] reconcile_inserts: Resolving images for 4 phrase(s) into: ..\\assets\\overlay_images\n",
      "[INFO] reconcile_inserts: Ensuring images for 4 phrase(s) into ..\\assets\\overlay_images\n",
      "[INFO] reconcile_inserts: [1/4] Resolving: 'a well constructed Union'\n",
      "[INFO] reconcile_inserts: [cache] MISS for anchor='union' (phrase: 'a well constructed Union')\n",
      "[INFO] reconcile_inserts: [replicate] Running model=black-forest-labs/flux-schnell prompt='In a 1780s style illustration output an image that represents the concept of a well constructed Union'\n",
      "[INFO] reconcile_inserts: [replicate] Succeeded\n",
      "[INFO] reconcile_inserts: [save] Wrote image -> ..\\assets\\overlay_images\\union.jpg\n",
      "[INFO] reconcile_inserts: [1/4] ✓ 'a well constructed Union' -> ..\\assets\\overlay_images\\union.jpg (source=replicate)\n",
      "[INFO] reconcile_inserts: [2/4] Resolving: 'Faction'\n",
      "[INFO] reconcile_inserts: [cache] HIT alias='faction' -> anchor='faction' -> ..\\assets\\overlay_images\\faction.jpg\n",
      "[INFO] reconcile_inserts: [2/4] ✓ 'Faction' -> ..\\assets\\overlay_images\\faction.jpg (source=cache)\n",
      "[INFO] reconcile_inserts: [3/4] Resolving: 'Their Propensity'\n",
      "[INFO] reconcile_inserts: [cache] HIT alias='their propensity' -> anchor='propensity' -> ..\\assets\\overlay_images\\propensity.jpg\n",
      "[INFO] reconcile_inserts: [3/4] ✓ 'Their Propensity' -> ..\\assets\\overlay_images\\propensity.jpg (source=cache)\n",
      "[INFO] reconcile_inserts: [4/4] Resolving: 'a Proper Cure'\n",
      "[INFO] reconcile_inserts: [cache] MISS for anchor='proper cure' (phrase: 'a Proper Cure')\n",
      "[INFO] reconcile_inserts: [replicate] Running model=black-forest-labs/flux-schnell prompt='In a 1780s style illustration output an image that represents the concept of a Proper Cure'\n",
      "[INFO] reconcile_inserts: [replicate] Succeeded\n",
      "[INFO] reconcile_inserts: [save] Wrote image -> ..\\assets\\overlay_images\\proper_cure.jpg\n",
      "[INFO] reconcile_inserts: [4/4] ✓ 'a Proper Cure' -> ..\\assets\\overlay_images\\proper_cure.jpg (source=replicate)\n",
      "[INFO] reconcile_inserts: All phrases resolved.\n",
      "[INFO] reconcile_inserts: Updated asset for 'a well constructed Union': ../assets/overlay_images/union.jpg -> ../assets/overlay_images/union.jpg\n",
      "[INFO] reconcile_inserts: Updated asset for 'Faction': ../assets/overlay_images/faction.jpg -> ../assets/overlay_images/faction.jpg\n",
      "[INFO] reconcile_inserts: Updated asset for 'Their Propensity': ../assets/overlay_images/propensity.jpg -> ../assets/overlay_images/propensity.jpg\n",
      "[INFO] reconcile_inserts: Updated asset for 'a Proper Cure': ../assets/overlay_images/proper_cure.jpg -> ../assets/overlay_images/proper_cure.jpg\n",
      "[INFO] reconcile_inserts: Saved updated inserts JSON: ..\\data\\captions\\federalist-10\\image_timestamps\\federalist-10-part-01-img-caption.json (assets updated: 4)\n"
     ]
    }
   ],
   "source": [
    "from video_inserts.image_cache_manager import ensure_images_for_phrases, get_or_create_image_for_phrase\n",
    "from video_inserts.reconcile_inserts_with_images import reconcile_inserts_json\n",
    "\n",
    "image_chunk_files = sorted([p for p in IMAGE_CAPTION_JSON_DIR.glob(\"*.json\") if p.name != \"manifest.json\"])\n",
    "\n",
    "# for image_chunk_path in image_chunk_files:\n",
    "if image_chunk_files:\n",
    "    image_chunk_path = image_chunk_files[0]\n",
    "    reconcile_inserts_json(\n",
    "        image_chunk_path,\n",
    "        overlay_dir=OVERLAY_IMAGE_DIR,\n",
    "        preferred_source=\"replicate\",\n",
    "        replicate_api_key=REPLICATE_API_KEY,\n",
    "        replicate_model=\"black-forest-labs/flux-schnell\",\n",
    "        replicate_inputs={\"width\": 1024, \"output_format\": \"jpg\"},\n",
    "        log_level=\"INFO\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15a220c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building video ..\\data\\video_output\\federalist-10\\image_overlays\\output.mp4.\n",
      "MoviePy - Writing audio in outputTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing video ..\\data\\video_output\\federalist-10\\image_overlays\\output.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame_index:  92%|█████████▏| 727/793 [02:03<00:11,  5.77it/s, now=None]c:\\Users\\cjmij\\anaconda3\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:190: UserWarning: In file ..\\data\\video_output\\federalist-10\\caption\\federalist-10-part-01-tts-caption.mp4, 6220800 bytes wanted but 0 bytes read at frame index 726 (out of a total 726 frames), at time 30.25/30.29 sec. Using the last valid frame instead.\n",
      "  warnings.warn(\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready ..\\data\\video_output\\federalist-10\\image_overlays\\output.mp4\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from moviepy import VideoFileClip, CompositeVideoClip\n",
    "# If your script is saved as overlay_from_json.py in the same folder:\n",
    "from video_inserts.overlay_from_json import _parse_inserts, build_overlays\n",
    "\n",
    "# Paths\n",
    "video_in = Path(\"../data/video_output/federalist-10/caption/federalist-10-part-01-tts-caption.mp4\")\n",
    "json_in = Path(\"../data/captions/federalist-10/image_timestamps/federalist-10-part-01-img-caption.json\")\n",
    "video_out = Path(\"../data/video_output/federalist-10/image_overlays/output.mp4\")\n",
    "\n",
    "base = VideoFileClip(str(video_in))\n",
    "base_w, base_h = base.size\n",
    "\n",
    "fps, inserts = _parse_inserts(json_in)\n",
    "overlays = build_overlays(base_w, base_h, inserts)\n",
    "\n",
    "comp = CompositeVideoClip([base] + overlays, size=(base_w, base_h))\n",
    "\n",
    "# Quick inline preview for short clips (MoviePy v2):\n",
    "# comp.preview(fps=fps)   # opens a window; for Jupyter, you can write to a temp mp4 and display.\n",
    "\n",
    "comp.write_videofile(\n",
    "    str(video_out),\n",
    "    codec=\"libx264\",\n",
    "    fps=fps or (base.fps if getattr(base, \"fps\", None) else 24),\n",
    "    ffmpeg_params=[\"-preset\", \"medium\", \"-crf\", \"18\", \"-pix_fmt\", \"yuv420p\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8a6f78",
   "metadata": {},
   "source": [
    "# Section 5: Commentary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5882af25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from commentary.ollama_commentary import process_json_file, process_many_json_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6349a6d",
   "metadata": {},
   "source": [
    "import requests, json\n",
    "try:\n",
    "    requests.post(\"http://localhost:11434/api/tags\", json={}).raise_for_status()\n",
    "    print(\"✅ Ollama API reachable\")\n",
    "except Exception as e:\n",
    "    print(\"⚠️ Ollama API not reachable:\", e)\n",
    "    print(\"Tip: start it with `ollama serve` in a terminal.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
